{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMVJP7HzvE8uiny30a15Hd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsPratik-cyber/mlprojectpratik/blob/main/DATA_cleaning_AUTO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Run Basic Data Quality Checks**"
      ],
      "metadata": {
        "id": "ne8NDG8mOCtf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmOHVIFYN16s"
      },
      "outputs": [],
      "source": [
        "def check_data_quality(df):\n",
        "    # Store initial data quality metrics\n",
        "    quality_report = {\n",
        "        'missing_values': df.isnull().sum().to_dict(),\n",
        "        'duplicates': df.duplicated().sum(),\n",
        "        'total_rows': len(df),\n",
        "        'memory_usage': df.memory_usage().sum() / 1024**2  # in MB\n",
        "    }\n",
        "    return quality_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Standardize Data Types**\n"
      ],
      "metadata": {
        "id": "CJLxfNvdOWdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_datatypes(df):\n",
        "    for column in df.columns:\n",
        "        # Try converting string dates to datetime\n",
        "        if df[column].dtype == 'object':\n",
        "            try:\n",
        "                df[column] = pd.to_datetime(df[column])\n",
        "                print(f\"Converted {column} to datetime\")\n",
        "            except ValueError:\n",
        "                # Try converting to numeric if datetime fails\n",
        "                try:\n",
        "                    df[column] = pd.to_numeric(df[column].str.replace('$', '').str.replace(',', ''))\n",
        "                    print(f\"Converted {column} to numeric\")\n",
        "                except:\n",
        "                    pass\n",
        "    return df"
      ],
      "metadata": {
        "id": "V4DbOs8YOLhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Handle Missing Values**\n",
        ""
      ],
      "metadata": {
        "id": "TncYFuvfOfU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def handle_missing_values(df):\n",
        "    # Handle numeric columns\n",
        "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    if len(numeric_columns) > 0:\n",
        "        num_imputer = SimpleImputer(strategy='median')\n",
        "        df[numeric_columns] = num_imputer.fit_transform(df[numeric_columns])\n",
        "\n",
        "    # Handle categorical columns\n",
        "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "    if len(categorical_columns) > 0:\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        df[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "D5v9ZGcNOj4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Detect and Handle Outliers**"
      ],
      "metadata": {
        "id": "t_HjGS5pOoyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(df):\n",
        "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    outliers_removed = {}\n",
        "\n",
        "    for column in numeric_columns:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Count outliers before removing\n",
        "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0]\n",
        "\n",
        "        # Cap the values instead of removing them\n",
        "        df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "        if outliers > 0:\n",
        "            outliers_removed[column] = outliers\n",
        "\n",
        "    return df, outliers_removed"
      ],
      "metadata": {
        "id": "47i5ZdsdOtZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Validate the Results**"
      ],
      "metadata": {
        "id": "mAQQytBcO26U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_cleaning(df, original_shape, cleaning_report):\n",
        "    validation_results = {\n",
        "        'rows_remaining': len(df),\n",
        "        'missing_values_remaining': df.isnull().sum().sum(),\n",
        "        'duplicates_remaining': df.duplicated().sum(),\n",
        "        'data_loss_percentage': (1 - len(df)/original_shape[0]) * 100\n",
        "    }\n",
        "\n",
        "    # Add validation results to the cleaning report\n",
        "    cleaning_report['validation'] = validation_results\n",
        "    return cleaning_report"
      ],
      "metadata": {
        "id": "A1YlNX0vO4pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIPELINE"
      ],
      "metadata": {
        "id": "2eBiEVQXO9YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def automated_cleaning_pipeline(df):\n",
        "    # Store original shape for reporting\n",
        "    original_shape = df.shape\n",
        "\n",
        "    # Initialize cleaning report\n",
        "    cleaning_report = {}\n",
        "\n",
        "    # Execute each step and collect metrics\n",
        "    cleaning_report['initial_quality'] = check_data_quality(df)\n",
        "\n",
        "    df = standardize_datatypes(df)\n",
        "    df = handle_missing_values(df)\n",
        "    df, outliers = remove_outliers(df)\n",
        "    cleaning_report['outliers_removed'] = outliers\n",
        "\n",
        "    # Validate and finalize report\n",
        "    cleaning_report = validate_cleaning(df, original_shape, cleaning_report)\n",
        "\n",
        "    return df, cleaning_report"
      ],
      "metadata": {
        "id": "0CTSbffyO_Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wrapping Up**"
      ],
      "metadata": {
        "id": "BYJs8ZWIPPWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As you can see, automating data cleaning not only saves time but also ensures consistency and reproducibility in your data preparation process. The pipeline I've shared handles common data quality issues while providing detailed reporting on the changes made.\n",
        "\n",
        "You might need to adjust the cleaning strategies based on your domain knowledge and specific requirements.\n",
        "\n",
        "Remember that while automation is helpful, you should always review the cleaning report and validate the results for your specific use case. Happy data cleaning!"
      ],
      "metadata": {
        "id": "duNShlNNPJlr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzwoBuC8POnF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}